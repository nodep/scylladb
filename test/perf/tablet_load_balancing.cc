/*
 * Copyright (C) 2024-present ScyllaDB
 */

/*
 * SPDX-License-Identifier: LicenseRef-ScyllaDB-Source-Available-1.0
 */

#include <fmt/ranges.h>
#include <bit>

#include <seastar/core/distributed.hh>
#include <seastar/core/app-template.hh>
#include <seastar/core/sstring.hh>
#include <seastar/core/thread.hh>
#include <seastar/core/reactor.hh>

#include "locator/tablets.hh"
#include "service/tablet_allocator.hh"
#include "locator/tablet_replication_strategy.hh"
#include "locator/network_topology_strategy.hh"
#include "locator/load_sketch.hh"
#include "test/lib/topology_builder.hh"
#include "replica/tablets.hh"
#include "locator/tablet_replication_strategy.hh"
#include "db/config.hh"
#include "schema/schema_builder.hh"
#include "service/storage_proxy.hh"
#include "db/system_keyspace.hh"

#include "test/perf/perf.hh"
#include "test/lib/log.hh"
#include "test/lib/cql_test_env.hh"
#include "test/lib/random_utils.hh"
#include "test/lib/key_utils.hh"

using namespace locator;
using namespace replica;
using namespace service;

static seastar::logger simlblog("simlb");

static seastar::abort_source aborted;

static const sstring dc = "dc1";

static
cql_test_config tablet_cql_test_config() {
    cql_test_config c;
    return c;
}

static
future<table_id> add_table(cql_test_env& e, sstring test_ks_name = "") {
    auto id = table_id(utils::UUID_gen::get_time_UUID());
    co_await e.create_table([&] (std::string_view ks_name) {
        if (!test_ks_name.empty()) {
            ks_name = test_ks_name;
        }
        return *schema_builder(ks_name, id.to_sstring(), id)
                .with_column("p1", utf8_type, column_kind::partition_key)
                .with_column("r1", int32_type)
                .build();
    });
    co_return id;
}

// Run in a seastar thread
static
sstring add_keyspace(cql_test_env& e, std::unordered_map<sstring, int> dc_rf, int initial_tablets = 0) {
    static std::atomic<int> ks_id = 0;
    auto ks_name = fmt::format("keyspace{}", ks_id.fetch_add(1));
    sstring rf_options;
    for (auto& [dc, rf] : dc_rf) {
        rf_options += format(", '{}': {}", dc, rf);
    }
    e.execute_cql(fmt::format("create keyspace {} with replication = {{'class': 'NetworkTopologyStrategy'{}}}"
                              " and tablets = {{'enabled': true, 'initial': {}}}",
                              ks_name, rf_options, initial_tablets)).get();
    return ks_name;
}

static
size_t get_tablet_count(const tablet_metadata& tm) {
    size_t count = 0;
    for (const auto& [table, tmap] : tm.all_tables_ungrouped()) {
        count += std::accumulate(tmap->tablets().begin(), tmap->tablets().end(), size_t(0),
                                 [] (size_t accumulator, const locator::tablet_info& info) {
                                     return accumulator + info.replicas.size();
                                 });
    }
    return count;
}

static
future<> apply_resize_plan(token_metadata& tm, const migration_plan& plan) {
    for (auto [table_id, resize_decision] : plan.resize_plan().resize) {
        co_await tm.tablets().mutate_tablet_map_async(table_id, [&resize_decision] (tablet_map& tmap) {
            resize_decision.sequence_number = tmap.resize_decision().sequence_number + 1;
            tmap.set_resize_decision(resize_decision);
            return make_ready_future();
        });
    }
    for (auto table_id : plan.resize_plan().finalize_resize) {
        auto& old_tmap = tm.tablets().get_tablet_map(table_id);
        simlblog.info("Setting new tablet map of size {}", old_tmap.tablet_count() * 2);
        tablet_map tmap(old_tmap.tablet_count() * 2);
        tm.tablets().set_tablet_map(table_id, std::move(tmap));
    }
}

// Reflects the plan in a given token metadata as if the migrations were fully executed.
static
future<> apply_plan(token_metadata& tm, const migration_plan& plan, locator::load_stats& load_stats) {
    for (auto&& mig : plan.migrations()) {
        co_await tm.tablets().mutate_tablet_map_async(mig.tablet.table, [&mig] (tablet_map& tmap) {
            auto tinfo = tmap.get_tablet_info(mig.tablet.tablet);
            tinfo.replicas = replace_replica(tinfo.replicas, mig.src, mig.dst);
            tmap.set_tablet(mig.tablet.tablet, tinfo);
            return make_ready_future();
        });
        // Update load_stats
        if (mig.src.host != mig.dst.host) {
            if (!load_stats.tablet_stats.contains(mig.src.host)) {
                throw std::runtime_error(format("Source host not found in load_stats for migration {}", mig));
            }
            if (!load_stats.tablet_stats.contains(mig.dst.host)) {
                throw std::runtime_error(format("Destination host not found in load_stats for migration {}", mig));
            }

            auto& src_stats = load_stats.tablet_stats.at(mig.src.host);
            auto& dst_stats = load_stats.tablet_stats.at(mig.dst.host);

            auto& tmap = tm.tablets().get_tablet_map(mig.tablet.table);
            const range_based_tablet_id rb_tid{mig.tablet.table, tmap.get_token_range(mig.tablet.tablet)};

            if (!src_stats.tablet_sizes.contains(rb_tid)) {
                throw std::runtime_error(format("Tablet not found on source load_stats for migration: {}", mig));
            }
            if (dst_stats.tablet_sizes.contains(rb_tid)) {
                throw std::runtime_error(format("Tablet already on destination load_stats for migration: {}", mig));
            }

            uint64_t used_disk_space = 0;
            for (auto size : std::views::values(dst_stats.tablet_sizes)) {
                used_disk_space += size;
            }
            const uint64_t tablet_size = src_stats.tablet_sizes.at(rb_tid);
            if (dst_stats.effective_capacity < used_disk_space + tablet_size) {
                throw std::runtime_error(format("Attempting to move tablet to host with insufficient disk capacity for migration: {}", mig));
            }
            dst_stats.tablet_sizes[rb_tid] = tablet_size;
            src_stats.tablet_sizes.erase(rb_tid);
        }
    }
    co_await apply_resize_plan(tm, plan);
}

using seconds_double = std::chrono::duration<double>;

struct rebalance_stats {
    seconds_double elapsed_time = seconds_double(0);
    seconds_double max_rebalance_time = seconds_double(0);
    uint64_t rebalance_count = 0;

    rebalance_stats& operator+=(const rebalance_stats& other) {
        elapsed_time += other.elapsed_time;
        max_rebalance_time = std::max(max_rebalance_time, other.max_rebalance_time);
        rebalance_count += other.rebalance_count;
        return *this;
    }
};

static
rebalance_stats rebalance_tablets(cql_test_env& e, lw_shared_ptr<locator::load_stats> load_stats, std::unordered_set<host_id> skiplist = {}) {
    rebalance_stats stats;
    abort_source as;

    auto guard = e.get_raft_group0_client().start_operation(as).get();
    auto& talloc = e.get_tablet_allocator().local();
    auto& stm = e.shared_token_metadata().local();

    // Sanity limit to avoid infinite loops.
    // The x10 factor is arbitrary, it's there to account for more complex schedules than direct migration.
    auto max_iterations = 1 + get_tablet_count(stm.get()->tablets()) * 10;

    for (size_t i = 0; i < max_iterations; ++i) {
        auto prev_lb_stats = talloc.stats().for_dc(dc);
        auto start_time = std::chrono::steady_clock::now();

        auto plan = talloc.balance_tablets(stm.get(), load_stats, skiplist).get();

        simlblog.debug("balance emited {} migrations", plan.migrations().size());
        for (const auto& mig : plan.migrations()) {
            dht::token_range range {stm.get()->tablets().get_tablet_map(mig.tablet.table).get_token_range(mig.tablet.tablet)};
            sstring kind = mig.src.host == mig.dst.host ? "intra" : "     ";
            simlblog.debug("  {} mig: {} src: {} dst: {} size: {}", kind, mig.tablet, mig.src, mig.dst,
                            bytes2gb(load_stats->get_tablet_size(mig.src.host, {mig.tablet.table, range}, service::default_target_tablet_size)));
        }

        auto end_time = std::chrono::steady_clock::now();
        auto lb_stats = talloc.stats().for_dc(dc) - prev_lb_stats;

        auto elapsed = std::chrono::duration_cast<seconds_double>(end_time - start_time);
        rebalance_stats iteration_stats = {
            .elapsed_time = elapsed,
            .max_rebalance_time = elapsed,
            .rebalance_count = 1,
        };
        stats += iteration_stats;
        simlblog.debug("Rebalance iteration {} took {:.3f} [s]: mig={}, bad={}, first_bad={}, eval={}, skiplist={}, skip: (load={}, rack={}, node={})",
                      i + 1, elapsed.count(),
                      lb_stats.migrations_produced,
                      lb_stats.bad_migrations,
                      lb_stats.bad_first_candidates,
                      lb_stats.candidates_evaluated,
                      lb_stats.migrations_from_skiplist,
                      lb_stats.migrations_skipped,
                      lb_stats.tablets_skipped_rack,
                      lb_stats.tablets_skipped_node);

        if (plan.empty()) {
            // We should not introduce inconsistency between on-disk state and in-memory state
            // as that may violate invariants and cause failures in later operations
            // causing test flakiness.
            save_tablet_metadata(e.local_db(), stm.get()->tablets(), guard.write_timestamp()).get();
            e.get_storage_service().local().update_tablet_metadata({}).get();
            simlblog.info("Rebalance took {:.3f} [s] after {} iteration(s)", stats.elapsed_time.count(), i + 1);
            return stats;
        }
        stm.mutate_token_metadata([&] (token_metadata& tm) {
            return apply_plan(tm, plan, *load_stats);
        }).get();
    }
    throw std::runtime_error("rebalance_tablets(): convergence not reached within limit");
}

struct params {
    int iterations;
    int nodes;
    std::optional<int> tablets1;
    std::optional<int> tablets2;
    int shards;
    int scale1 = 1;
    int scale2 = 1;
    unsigned int seed;
    std::vector<unsigned> capacities = {650};
    bool high_tablet_size_variability = false;
};

struct table_balance {
    double shard_overcommit;
    double node_overcommit;
};

constexpr auto nr_tables = 2;

struct cluster_balance {
    table_balance tables[nr_tables];
};

struct results {
    cluster_balance init;
    cluster_balance worst;
    cluster_balance last;
    rebalance_stats stats;
};

template<>
struct fmt::formatter<table_balance> : fmt::formatter<string_view> {
    template <typename FormatContext>
    auto format(const table_balance& b, FormatContext& ctx) const {
        return fmt::format_to(ctx.out(), "{{shard={:.2f} node={:.2f}}}",
                              b.shard_overcommit, b.node_overcommit);
    }
};

template<>
struct fmt::formatter<cluster_balance> : fmt::formatter<string_view> {
    template <typename FormatContext>
    auto format(const cluster_balance& r, FormatContext& ctx) const {
        return fmt::format_to(ctx.out(), "{{table1={}, table2={}}}", r.tables[0], r.tables[1]);
    }
};

template<>
struct fmt::formatter<params> : fmt::formatter<string_view> {
    template <typename FormatContext>
    auto format(const params& p, FormatContext& ctx) const {
        auto tablets1_per_shard = double(p.tablets1.value_or(0)) / (p.nodes * p.shards);
        auto tablets2_per_shard = double(p.tablets2.value_or(0)) / (p.nodes * p.shards);
        return fmt::format_to(ctx.out(), "{{iterations={}, nodes={}, tablets1={} ({:0.1f}/sh), tablets2={} ({:0.1f}/sh), shards={}, seed={}, capacities={}, high_tablet_size_variability={}}}",
                         p.iterations, p.nodes,
                         p.tablets1.value_or(0), tablets1_per_shard,
                         p.tablets2.value_or(0), tablets2_per_shard,
                         p.shards,
                         p.seed, p.capacities, p.high_tablet_size_variability);
    }
};

struct tablet_size_generator {
    static constexpr uint64_t huge_tablet_size_threshold = default_target_tablet_size * 10;

    size_t tablet_count = 0;
    bool use_high_variability = false;

    tests::random::stepped_int_distribution<size_t> moderate_variability {{
        {97.9, {1,                                  default_target_tablet_size * 2}},
        { 2.0, {default_target_tablet_size * 2 + 1, huge_tablet_size_threshold}},
        { 0.1, {huge_tablet_size_threshold + 1,     huge_tablet_size_threshold * 5}},
    }};

    tests::random::stepped_int_distribution<size_t> high_variability {{
        {90.0, {1,                                  default_target_tablet_size * 2}},
        { 9.0, {default_target_tablet_size * 2 + 1, huge_tablet_size_threshold}},
        { 1.0, {huge_tablet_size_threshold + 1,     huge_tablet_size_threshold * 5}},
    }};

    explicit tablet_size_generator(const params& p)
        : use_high_variability(p.high_tablet_size_variability) {
    }

    uint64_t generate() {
        if (use_high_variability) {
            return high_variability(tests::random::gen());
        }

        return moderate_variability(tests::random::gen());
    }
};

future<results> test_load_balancing_with_many_tables(params p) {
    auto cfg = tablet_cql_test_config();
    results global_res;
    co_await do_with_cql_env_thread([&] (auto& e) {
        const int n_hosts = p.nodes;
        const shard_id shard_count = p.shards;
        const int cycles = p.iterations;

        topology_builder topo(e);
        std::vector<host_id> hosts;
        lw_shared_ptr<locator::load_stats> stats = make_lw_shared<locator::load_stats>();
        stats->tablet_stats = tablet_load_stats_map{};

        uint64_t total_capacity = 0;
        auto add_host = [&] {
            static int added_hosts = 0;
            auto host = topo.add_node(service::node_state::normal, shard_count);
            hosts.push_back(host);
            const uint64_t capacity = p.capacities[added_hosts % p.capacities.size()] * 1024L * 1024L * 1024L * shard_count;
            stats->capacity[host] = capacity;
            stats->tablet_stats[host].effective_capacity = capacity;
            total_capacity += capacity;
            simlblog.info("Added new node: {}", host);
            added_hosts++;
        };

        for (int i = 0; i < n_hosts; ++i) {
            add_host();
        }

        auto& stm = e.shared_token_metadata().local();

        auto bootstrap = [&] {
            add_host();
            global_res.stats += rebalance_tablets(e, stats);
        };

        auto decommission = [&] (host_id host) {
            auto i = std::distance(hosts.begin(), std::find(hosts.begin(), hosts.end(), host));
            if ((size_t)i == hosts.size()) {
                throw std::runtime_error(format("No such host: {}", host));
            }
            topo.set_node_state(host, service::node_state::decommissioning);
            global_res.stats += rebalance_tablets(e, stats);
            if (stm.get()->tablets().has_replica_on(host)) {
                throw std::runtime_error(format("Host {} still has replicas!", host));
            }
            topo.set_node_state(host, service::node_state::left);
            simlblog.info("Node decommissioned: {}", host);
            hosts.erase(hosts.begin() + i);
            total_capacity -= stats->capacity.at(host);
            stats->tablet_stats.erase(host);
        };

        auto ks1 = add_keyspace(e, {{topo.dc(), 1}}, p.tablets1.value_or(1));
        auto ks2 = add_keyspace(e, {{topo.dc(), 1}}, p.tablets2.value_or(1));
        auto id1 = add_table(e, ks1).get();
        auto id2 = add_table(e, ks2).get();
        schema_ptr s1 = e.local_db().find_schema(id1);
        schema_ptr s2 = e.local_db().find_schema(id2);

        std::unordered_map<table_id, uint64_t> table_sizes;

        // generate tablet sizes
        std::unordered_map<host_id, uint64_t> used_disk_space;
        tablet_size_generator tsg(p);
        for (auto&& [table, tmap] : stm.get()->tablets().all_tables_ungrouped()) {
            tmap->for_each_tablet([&] (tablet_id tid, const tablet_info& ti) -> future<> {
                for (const auto& replica : ti.replicas) {
                    const uint64_t tablet_size = tsg.generate();
                    used_disk_space[replica.host] += tablet_size;
                    locator::tablet_load_stats& tls = stats->tablet_stats[replica.host];
                    if (used_disk_space[replica.host] > tls.effective_capacity) {
                        throw std::runtime_error("Not enough disk capacity to allocate tablets for the selected topology.");
                    }
                    locator::range_based_tablet_id rb_tid {table, tmap->get_token_range(tid)};
                    tls.tablet_sizes[rb_tid] = tablet_size;
                    table_sizes[table] += tablet_size;
                    simlblog.debug("generated tablet size {} for {}:{}", tablet_size, table, tid);
                }
                return make_ready_future<>();
            }).get();
        }

        auto check_balance = [&] () -> cluster_balance {
            cluster_balance res;

            simlblog.debug("tablet metadata: {}", stm.get()->tablets());

            int table_index = 0;
            for (auto s : {s1, s2}) {
                load_sketch load(stm.get(), stats);
                load.populate(std::nullopt, s->id()).get();
                load.dump(format("for table: {}", s->id()));

                auto ideal_load = double(table_sizes[s->id()]) / total_capacity;
                min_max_tracker<double> shard_load_minmax;
                min_max_tracker<double> node_load_minmax;
                double sum_node_load = 0;
                for (auto h: hosts) {
                    auto minmax = load.get_shard_minmax(h);
                    auto node_load = load.get_load(h);
                    auto avg_tablet_count = load.get_real_avg_tablet_count(h);
                    auto overcommit = minmax.max() / ideal_load;
                    shard_load_minmax.update(minmax.max());
                    simlblog.info("Load on host {} for table {}: total={}, min={}, max={}, spread={}, avg_tablets={:.2f}, overcommit={:.2f}",
                                 h, s->cf_name(), node_load, minmax.min(), minmax.max(), minmax.max() - minmax.min(), avg_tablet_count, overcommit);
                    node_load_minmax.update(node_load);
                    sum_node_load += node_load;
                }

                // Overcommit given the best distribution of tablets given current table size.
                auto avg_node_load = sum_node_load / hosts.size();
                auto shard_overcommit = shard_load_minmax.max() / ideal_load;
                simlblog.info("Shard overcommit: {}", shard_overcommit);

                auto node_imbalance = node_load_minmax.max() - node_load_minmax.min();
                auto node_overcommit = node_load_minmax.max() / ideal_load;
                simlblog.info("Node imbalance: min={}, max={}, spread={}, avg={:.2f}, overcommit={:.2f}",
                              node_load_minmax.min(), node_load_minmax.max(), node_imbalance, avg_node_load, node_overcommit);

                res.tables[table_index++] = {
                    .shard_overcommit = shard_overcommit,
                    .node_overcommit = node_overcommit
                };
            }

            for (int i = 0; i < nr_tables; i++) {
                auto t = res.tables[i];
                global_res.worst.tables[i].shard_overcommit = std::max(global_res.worst.tables[i].shard_overcommit, t.shard_overcommit);
                global_res.worst.tables[i].node_overcommit = std::max(global_res.worst.tables[i].node_overcommit, t.node_overcommit);
            }

            simlblog.info("Overcommit: {}", res);
            return res;
        };

        simlblog.debug("tablet metadata: {}", stm.get()->tablets());

        check_balance();

        rebalance_tablets(e, stats);

        global_res.init = global_res.worst = check_balance();

        for (int i = 0; i < cycles; i++) {
            bootstrap();
            check_balance();

            decommission(hosts[0]);
            global_res.last = check_balance();
        }
    }, cfg);
    co_return global_res;
}

future<> run_simulation(const params& p, const sstring& name = "") {
    simlblog.info("[run {}] params: {}", name, p);

    auto total_tablet_count = p.tablets1.value_or(0) + p.tablets2.value_or(0);
    simlblog.info("[run {}] tablet count: {}", name, total_tablet_count);
    simlblog.info("[run {}] tablet count / shard: {:.3f}", name, double(total_tablet_count) / (p.nodes * p.shards));

    auto res = co_await test_load_balancing_with_many_tables(p);
    simlblog.info("[run {}] Overcommit       : init : {}", name, res.init);
    simlblog.info("[run {}] Overcommit       : worst: {}", name, res.worst);
    simlblog.info("[run {}] Overcommit       : last : {}", name, res.last);
    simlblog.info("[run {}] Overcommit       : time : {:.3f} [s], max={:.3f} [s], count={}", name,
                 res.stats.elapsed_time.count(), res.stats.max_rebalance_time.count(), res.stats.rebalance_count);

    if (res.stats.elapsed_time > seconds_double(1)) {
        simlblog.warn("[run {}] Scheduling took longer than 1s!", name);
    }

    for (int i = 0; i < nr_tables; ++i) {
        auto overcommit = res.worst.tables[i].shard_overcommit;
        if (overcommit > 1.2) {
            simlblog.warn("[run {}] table{} shard overcommit {:.2f} > 1.2!", name, i + 1, overcommit);
        }
    }
}

future<> run_simulations(const boost::program_options::variables_map& app_cfg, unsigned seed) {
    for (auto i = 0; i < app_cfg["runs"].as<int>(); i++) {
        auto shards = 1 << tests::random::get_int(0, 8);
        auto scale1 = 1 << tests::random::get_int(0, 5);
        auto scale2 = 1 << tests::random::get_int(0, 5);
        auto nodes = tests::random::get_int(3, 6);
        params p {
            .iterations = app_cfg["iterations"].as<int>(),
            .nodes = nodes,
            .tablets1 = std::bit_ceil<size_t>(shards * nodes * scale1),
            .tablets2 = std::bit_ceil<size_t>(shards * nodes * scale2),
            .shards = shards,
            .scale1 = scale1,
            .scale2 = scale2,
            .seed = seed,
        };

        auto name = format("#{}", i);
        co_await run_simulation(p, name);
    }
}

namespace perf {

int scylla_tablet_load_balancing_main(int argc, char** argv) {
    namespace bpo = boost::program_options;
    app_template app;
    app.add_options()
            ("runs", bpo::value<int>(), "Number of simulation runs.")
            ("iterations", bpo::value<int>()->default_value(8), "Number of topology-changing cycles in each run.")
            ("nodes", bpo::value<int>(), "Number of nodes in the cluster.")
            ("tablets1", bpo::value<int>(), "Number of tablets for the first table.")
            ("tablets2", bpo::value<int>(), "Number of tablets for the second table.")
            ("shards", bpo::value<int>(), "Number of shards per node.")
            ("seed", bpo::value<unsigned>(), "Tablet size random generator seed.")
            ("capacities", bpo::value<std::vector<unsigned>>()->multitoken(), "Disk capacity per shard in GB; can have muiltiple values.")
            ("high_tablet_size_variability", bpo::value<bool>(), "Enable higher tablet size variability.")
            ("verbose", "Enables standard logging")
            ;
    return app.run(argc, argv, [&] {
        return seastar::async([&] {
            if (!app.configuration().contains("verbose")) {
                auto simlblog_level = logging::logger_registry().get_logger_level("simlb");
                logging::logger_registry().set_all_loggers_level(seastar::log_level::warn);
                logging::logger_registry().set_logger_level("simlb", simlblog_level);
            }
            auto stop_test = defer([] {
                aborted.request_abort();
            });

            logalloc::prime_segment_pool(memory::stats().total_memory(), memory::min_free_memory()).get();
            try {
                unsigned seed = 0;
                if (app.configuration().contains("seed")) {
                    seed = app.configuration()["seed"].as<unsigned>();
                } else {
                    seed = std::random_device{}();
                }
                testing::local_random_engine.seed(seed);

                if (app.configuration().contains("runs")) {
                    run_simulations(app.configuration(), seed).get();
                } else {
                    params p {
                        .iterations = app.configuration()["iterations"].as<int>(),
                        .nodes = app.configuration()["nodes"].as<int>(),
                        .tablets1 = app.configuration()["tablets1"].as<int>(),
                        .tablets2 = app.configuration()["tablets2"].as<int>(),
                        .shards = app.configuration()["shards"].as<int>(),
                        .seed = seed,
                    };

                    if (app.configuration().contains("capacities")) {
                        p.capacities = app.configuration()["capacities"].as<std::vector<unsigned>>();
                    }
                    if (app.configuration().contains("high_tablet_size_variability")) {
                        p.high_tablet_size_variability = app.configuration()["high_tablet_size_variability"].as<bool>();
                    }
                    run_simulation(p).get();
                }
            } catch (seastar::abort_requested_exception&) {
                // Ignore
            }
        });
    });
}

} // namespace perf
